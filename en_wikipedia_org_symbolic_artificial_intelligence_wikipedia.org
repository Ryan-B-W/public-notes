:PROPERTIES:
:ID:       38899cf2-da30-45e5-85dc-7ce7c5d40409
:ROAM_REFS: https://en.wikipedia.org/wiki/Symbolic_artificial_intelligence
:END:
#+title: (en.wikipedia.org) Symbolic artificial intelligence - Wikipedia
#+filetags: :artificial_intelligence:computer_science:website:

#+begin_quote
  In [[https://en.wikipedia.org/wiki/Artificial_intelligence][artificial intelligence]], *symbolic artificial intelligence* (also known as *classical artificial intelligence* or *logic-based artificial intelligence*) is the term for the collection of all methods in artificial intelligence research that are based on high-level [[https://en.wikipedia.org/wiki/Physical_symbol_systems_hypothesis][symbolic]] (human-readable) representations of problems, [[https://en.wikipedia.org/wiki/Formal_logic][logic]] and [[https://en.wikipedia.org/wiki/Search_algorithm][search]].  Symbolic AI used tools such as [[https://en.wikipedia.org/wiki/Logic_programming][logic programming]], [[https://en.wikipedia.org/wiki/Production_(computer_science)][production rules]], [[https://en.wikipedia.org/wiki/Semantic_nets][semantic nets]] and [[https://en.wikipedia.org/wiki/Frame_(artificial_intelligence)][frames]], and it developed applications such as [[https://en.wikipedia.org/wiki/Knowledge-based_systems][knowledge-based systems]] (in particular, [[https://en.wikipedia.org/wiki/Expert_systems][expert systems]]), [[https://en.wikipedia.org/wiki/Symbolic_mathematics][symbolic mathematics]], [[https://en.wikipedia.org/wiki/Automated_theorem_provers][automated theorem provers]], [[https://en.wikipedia.org/wiki/Ontologies][ontologies]], the [[https://en.wikipedia.org/wiki/Semantic_web][semantic web]], and [[https://en.wikipedia.org/wiki/Automated_planning_and_scheduling][automated planning and scheduling]] systems.  The Symbolic AI paradigm led to seminal ideas in [[https://en.wikipedia.org/wiki/Artificial_intelligence#Search_and_optimization][search]], [[https://en.wikipedia.org/wiki/Symbolic_programming][symbolic programming]] languages, [[https://en.wikipedia.org/wiki/Intelligent_agent][agents]], [[https://en.wikipedia.org/wiki/Multi-agent_systems][multi-agent systems]], the [[https://en.wikipedia.org/wiki/Semantic_web][semantic web]], and the strengths and limitations of formal knowledge and [[https://en.wikipedia.org/wiki/Automated_reasoning][reasoning systems]].

  Symbolic AI was the dominant [[https://en.wikipedia.org/wiki/Paradigm][paradigm]] of AI research from the mid-1950s until the mid-1990s.  Researchers in the 1960s and the 1970s were convinced that symbolic approaches would eventually succeed in creating a machine with [[https://en.wikipedia.org/wiki/Artificial_general_intelligence][artificial general intelligence]] and considered this the ultimate goal of their field.  An early boom, with early successes such as the [[https://en.wikipedia.org/wiki/Logic_Theorist][Logic Theorist]] and [[https://en.wikipedia.org/wiki/Arthur_Samuel_(computer_scientist)][Samuel]]'s [[https://en.wikipedia.org/wiki/Arthur_Samuel_(computer_scientist)][Checkers Playing Program]], led to unrealistic expectations and promises and was followed by the first [[https://en.wikipedia.org/wiki/AI_winter][AI Winter]] as funding dried up.  A second boom (1969--1986) occurred with the rise of expert systems, their promise of capturing corporate expertise, and an enthusiastic corporate embrace.  That boom, and some early successes, e.g., with [[https://en.wikipedia.org/wiki/XCON][XCON]] at [[https://en.wikipedia.org/wiki/Digital_Equipment_Corporation][DEC]], was followed again by later disappointment.  Problems with difficulties in knowledge acquisition, maintaining large knowledge bases, and brittleness in handling out-of-domain problems arose.  Another, second, AI Winter (1988--2011) followed.  Subsequently, AI researchers focused on addressing underlying problems in handling uncertainty and in knowledge acquisition.  Uncertainty was addressed with formal methods such as [[https://en.wikipedia.org/wiki/Hidden_Markov_model][hidden Markov models]], [[https://en.wikipedia.org/wiki/Bayesian_reasoning][Bayesian reasoning]], and [[https://en.wikipedia.org/wiki/Statistical_relational_learning][statistical relational learning]].  Symbolic machine learning addressed the knowledge acquisition problem with contributions including [[https://en.wikipedia.org/wiki/Version_space_learning][Version Space]], [[https://en.wikipedia.org/wiki/Leslie_Valiant][Valiant]]'s [[https://en.wikipedia.org/wiki/Probably_approximately_correct_learning][PAC learning]], [[https://en.wikipedia.org/wiki/Ross_Quinlan][Quinlan]]'s [[https://en.wikipedia.org/wiki/ID3_algorithm][ID3]] [[https://en.wikipedia.org/wiki/Decision-tree][decision-tree]] learning, [[https://en.wikipedia.org/wiki/Case-based_reasoning][case-based learning]], and [[https://en.wikipedia.org/wiki/Inductive_logic_programming][inductive logic programming]] to learn relations.

  [[https://en.wikipedia.org/wiki/Artificial_neural_network][Neural networks]], a subsymbolic approach, had been pursued from early days and reemerged strongly in 2012.  Early examples are [[https://en.wikipedia.org/wiki/Frank_Rosenblatt][Rosenblatt]]'s [[https://en.wikipedia.org/wiki/Perceptron][perceptron]] learning work, the [[https://en.wikipedia.org/wiki/Backpropagation][backpropagation]] work of Rumelhart, Hinton and Williams, and work in [[https://en.wikipedia.org/wiki/Convolutional_neural_network][convolutional neural networks]] by LeCun et al. in 1989.  However, neural networks were not viewed as successful until about 2012: "Until Big Data became commonplace, the general consensus in the Al community was that the so-called neural-network approach was hopeless.  Systems just didn't work that well, compared to other methods.  ... A revolution came in 2012, when a number of people, including a team of researchers working with Hinton, worked out a way to use the power of [[https://en.wikipedia.org/wiki/GPUs][GPUs]] to enormously increase the power of neural networks." Over the next several years, [[https://en.wikipedia.org/wiki/Deep_learning][deep learning]] had spectacular success in handling vision, [[https://en.wikipedia.org/wiki/Speech_recognition][speech recognition]], speech synthesis, image generation, and machine translation.  However, since 2020, as inherent difficulties with bias, explanation, comprehensibility, and robustness became more apparent with deep learning approaches; an increasing number of AI researchers have called for [[https://en.wikipedia.org/wiki/Neuro-symbolic_AI][combining]] the best of both the symbolic and neural network approaches and addressing areas that both approaches have difficulty with, such as [[https://en.wikipedia.org/wiki/Commonsense_reasoning][common-sense reasoning]].
#+end_quote
