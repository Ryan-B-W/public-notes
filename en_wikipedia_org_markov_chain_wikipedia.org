:PROPERTIES:
:ID:       92c6a78e-f5d2-4238-a9c1-e655840d06f1
:ROAM_REFS: https://en.wikipedia.org/wiki/Markov_chain
:END:
#+title: (en.wikipedia.org) Markov chain - Wikipedia
#+filetags: :statistics_and_probability:website:

#+begin_quote
  In probability theory and statistics, a Markov chain or Markov process is a stochastic process describing a sequence of possible events in which the probability of each event depends only on the state attained in the previous event.  Informally, this may be thought of as, "What happens next depends only on the state of affairs now." A countably infinite sequence, in which the chain moves state at discrete time steps, gives a discrete-time Markov chain (DTMC).  A continuous-time process is called a continuous-time Markov chain (CTMC).  Markov processes are named in honor of the Russian mathematician Andrey Markov.
  Markov chains have many applications as statistical models of real-world processes.  They provide the basis for general stochastic simulation methods known as Markov chain Monte Carlo, which are used for simulating sampling from complex probability distributions, and have found application in areas including Bayesian statistics, biology, chemistry, economics, finance, information theory, physics, signal processing, and speech processing.
  The adjectives Markovian and Markov are used to describe something that is related to a Markov process.
#+end_quote
